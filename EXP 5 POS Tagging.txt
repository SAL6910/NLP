import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
stop_words = set(stopwords.words('english'))
 
text = "Hello welcome to the world of to learn Categorizing and POS Tagging with NLTK and Python"
 
tokenized = sent_tokenize(text)
for i in tokenized:
     
    # Word tokenizers is used to find the words
    # and punctuation in a string
    wordsList = nltk.word_tokenize(i)
 
    # removing stop words from wordList
    wordsList = [w for w in wordsList if not w in stop_words]
 
    #  Using a Tagger. Which is part-of-speech
    # tagger or POS-tagger.
    tagged = nltk.pos_tag(wordsList)
 
    print(tagged)


Output:

[('Hello', 'NNP'), ('welcome', 'JJ'), ('world', 'NN'), ('learn', 'NN'), ('Categorizing', 'NNP'), ('POS', 'NNP'), ('Tagging', 'NNP'), ('NLTK', 'NNP'), ('Python', 'NNP')]